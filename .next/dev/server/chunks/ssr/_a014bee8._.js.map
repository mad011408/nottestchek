{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 6, "column": 0}, "map": {"version":3,"sources":["file:///home/runner/workspace/lib/utils/shiki.tsx"],"sourcesContent":["import { Component, type ReactNode } from \"react\";\nimport { bundledLanguagesInfo } from \"shiki/langs\";\n\n// Create a Set of all supported language IDs and aliases from Shiki\nconst SUPPORTED_LANGUAGES = new Set(\n  bundledLanguagesInfo.flatMap((lang) => [lang.id, ...(lang.aliases || [])]),\n);\n\nexport const isLanguageSupported = (lang: string | undefined): boolean => {\n  if (!lang) return false;\n  return SUPPORTED_LANGUAGES.has(lang.toLowerCase());\n};\n\ninterface ShikiBoundaryProps {\n  fallback: ReactNode;\n  children: ReactNode;\n}\n\ninterface ShikiBoundaryState {\n  hasError: boolean;\n}\n\nexport class ShikiErrorBoundary extends Component<\n  ShikiBoundaryProps,\n  ShikiBoundaryState\n> {\n  state: ShikiBoundaryState = { hasError: false };\n\n  static getDerivedStateFromError(error: Error) {\n    console.log(\"[ShikiErrorBoundary] Caught error:\", error.message);\n    return { hasError: true };\n  }\n\n  componentDidCatch(error: Error) {\n    console.log(\n      \"[ShikiErrorBoundary] Error caught and suppressed:\",\n      error.message,\n    );\n  }\n\n  render() {\n    const { hasError } = this.state;\n    return hasError ? this.props.fallback : this.props.children;\n  }\n}\n"],"names":[],"mappings":";;;;;;AAAA;AACA;;;;;;;AAEA,oEAAoE;AACpE,MAAM,sBAAsB,IAAI,IAC9B,oJAAoB,CAAC,OAAO,CAAC,CAAC,OAAS;QAAC,KAAK,EAAE;WAAM,KAAK,OAAO,IAAI,EAAE;KAAE;AAGpE,MAAM,sBAAsB,CAAC;IAClC,IAAI,CAAC,MAAM,OAAO;IAClB,OAAO,oBAAoB,GAAG,CAAC,KAAK,WAAW;AACjD;AAWO,MAAM,2BAA2B,iaAAS;IAI/C,QAA4B;QAAE,UAAU;IAAM,EAAE;IAEhD,OAAO,yBAAyB,KAAY,EAAE;QAC5C,QAAQ,GAAG,CAAC,sCAAsC,MAAM,OAAO;QAC/D,OAAO;YAAE,UAAU;QAAK;IAC1B;IAEA,kBAAkB,KAAY,EAAE;QAC9B,QAAQ,GAAG,CACT,qDACA,MAAM,OAAO;IAEjB;IAEA,SAAS;QACP,MAAM,EAAE,QAAQ,EAAE,GAAG,IAAI,CAAC,KAAK;QAC/B,OAAO,WAAW,IAAI,CAAC,KAAK,CAAC,QAAQ,GAAG,IAAI,CAAC,KAAK,CAAC,QAAQ;IAC7D;AACF"}},
    {"offset": {"line": 52, "column": 0}, "map": {"version":3,"sources":["file:///home/runner/workspace/lib/token-utils.ts"],"sourcesContent":["import { UIMessage, UIMessagePart } from \"ai\";\nimport { countTokens, encode, decode } from \"gpt-tokenizer\";\nimport type { SubscriptionTier } from \"@/types\";\nimport type { Id } from \"@/convex/_generated/dataModel\";\n\nexport const MAX_TOKENS_FREE = 16000;\nexport const MAX_TOKENS_PRO_AND_TEAM = 32000;\nexport const MAX_TOKENS_ULTRA = 100000;\n/**\n * Maximum total tokens allowed across all files\n */\nexport const MAX_TOKENS_FILE = 24000;\n\nexport const getMaxTokensForSubscription = (\n  subscription: SubscriptionTier,\n): number => {\n  if (subscription === \"ultra\") return MAX_TOKENS_ULTRA;\n  if (subscription === \"pro\" || subscription === \"team\")\n    return MAX_TOKENS_PRO_AND_TEAM;\n  return MAX_TOKENS_FREE;\n};\n\n// Token limits for different contexts\nexport const STREAM_MAX_TOKENS = 2048;\nexport const TOOL_DEFAULT_MAX_TOKENS = 2048;\n\n// Truncation messages\nexport const TRUNCATION_MESSAGE =\n  \"\\n\\n[... OUTPUT TRUNCATED - middle content removed to fit context limits ...]\\n\\n\";\nexport const FILE_READ_TRUNCATION_MESSAGE =\n  \"\\n\\n[Content truncated due to size limit. Use line ranges to read in chunks]\";\nexport const TIMEOUT_MESSAGE = (seconds: number, pid?: number) =>\n  pid\n    ? `\\n\\nCommand output paused after ${seconds} seconds. Command continues in background with PID: ${pid}`\n    : `\\n\\nCommand output paused after ${seconds} seconds. Command continues in background.`;\n\n/**\n * Count tokens for a single message part\n */\nconst countPartTokens = (\n  part: UIMessagePart<any, any>,\n  fileTokens: Record<Id<\"files\">, number> = {},\n): number => {\n  if (part.type === \"text\" && \"text\" in part) {\n    return countTokens((part as { text?: string }).text || \"\");\n  }\n  if (\n    part.type === \"file\" &&\n    \"fileId\" in part &&\n    (part as { fileId?: Id<\"files\"> }).fileId\n  ) {\n    const fileId = (part as { fileId: Id<\"files\"> }).fileId;\n    return fileTokens[fileId] || 0;\n  }\n  // For tool-call, tool-result, and other part types, count their JSON structure\n  return countTokens(JSON.stringify(part));\n};\n\n/**\n * Extracts and counts tokens from message text and file tokens (excluding reasoning blocks)\n */\nconst getMessageTokenCountWithFiles = (\n  message: UIMessage,\n  fileTokens: Record<Id<\"files\">, number> = {},\n): number => {\n  // Filter out reasoning blocks before counting tokens\n  const partsWithoutReasoning = message.parts.filter(\n    (part) => part.type !== \"step-start\" && part.type !== \"reasoning\",\n  );\n\n  // Count tokens for all parts\n  const totalTokens = partsWithoutReasoning.reduce(\n    (sum, part) => sum + countPartTokens(part, fileTokens),\n    0,\n  );\n\n  return totalTokens;\n};\n\n/**\n * Truncates messages to stay within token limit, keeping newest messages first\n */\nexport const truncateMessagesToTokenLimit = (\n  messages: UIMessage[],\n  fileTokens: Record<Id<\"files\">, number> = {},\n  maxTokens: number = MAX_TOKENS_FREE,\n): UIMessage[] => {\n  if (messages.length === 0) return messages;\n\n  const result: UIMessage[] = [];\n  let totalTokens = 0;\n\n  // Process from newest to oldest\n  for (let i = messages.length - 1; i >= 0; i--) {\n    const messageTokens = getMessageTokenCountWithFiles(\n      messages[i],\n      fileTokens,\n    );\n\n    if (totalTokens + messageTokens > maxTokens) break;\n\n    totalTokens += messageTokens;\n    result.unshift(messages[i]);\n  }\n\n  return result;\n};\n\n/**\n * Counts total tokens in all messages\n */\nexport const countMessagesTokens = (\n  messages: UIMessage[],\n  fileTokens: Record<Id<\"files\">, number> = {},\n): number => {\n  return messages.reduce(\n    (total, message) =>\n      total + getMessageTokenCountWithFiles(message, fileTokens),\n    0,\n  );\n};\n\n/**\n * Truncates content by token count using 25% head + 75% tail strategy.\n * This preserves both the command start (context) and the end (final results/errors),\n * which is typically more useful for debugging than keeping only the beginning.\n */\nexport const truncateContent = (\n  content: string,\n  marker: string = TRUNCATION_MESSAGE,\n): string => {\n  const tokens = encode(content);\n  if (tokens.length <= TOOL_DEFAULT_MAX_TOKENS) return content;\n\n  const markerTokens = countTokens(marker);\n  if (TOOL_DEFAULT_MAX_TOKENS <= markerTokens) {\n    return TOOL_DEFAULT_MAX_TOKENS <= 0\n      ? \"\"\n      : decode(encode(marker).slice(-TOOL_DEFAULT_MAX_TOKENS));\n  }\n\n  const budgetForContent = TOOL_DEFAULT_MAX_TOKENS - markerTokens;\n\n  // 25% head + 75% tail strategy\n  const headBudget = Math.floor(budgetForContent * 0.25);\n  const tailBudget = budgetForContent - headBudget;\n\n  const headTokens = tokens.slice(0, headBudget);\n  const tailTokens = tokens.slice(-tailBudget);\n\n  return decode(headTokens) + marker + decode(tailTokens);\n};\n\n/**\n * Slices content to fit within a specific token budget\n */\nexport const sliceByTokens = (content: string, maxTokens: number): string => {\n  if (maxTokens <= 0) return \"\";\n\n  const tokens = encode(content);\n  if (tokens.length <= maxTokens) return content;\n\n  return decode(tokens.slice(0, maxTokens));\n};\n\n/**\n * Counts tokens for user input including text and uploaded files\n */\nexport const countInputTokens = (\n  input: string,\n  uploadedFiles: Array<{ tokens?: number }> = [],\n): number => {\n  const textTokens = countTokens(input);\n  const fileTokens = uploadedFiles.reduce(\n    (total, file) => total + (file.tokens || 0),\n    0,\n  );\n  return textTokens + fileTokens;\n};\n\n/**\n * Legacy wrapper for backward compatibility\n */\nexport function truncateOutput(args: {\n  content: string;\n  mode?: \"read-file\" | \"generic\";\n}): string {\n  const { content, mode } = args;\n  const suffix =\n    mode === \"read-file\" ? FILE_READ_TRUNCATION_MESSAGE : TRUNCATION_MESSAGE;\n  return truncateContent(content, suffix);\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AACA;AAAA;;AAIO,MAAM,kBAAkB;AACxB,MAAM,0BAA0B;AAChC,MAAM,mBAAmB;AAIzB,MAAM,kBAAkB;AAExB,MAAM,8BAA8B,CACzC;IAEA,IAAI,iBAAiB,SAAS,OAAO;IACrC,IAAI,iBAAiB,SAAS,iBAAiB,QAC7C,OAAO;IACT,OAAO;AACT;AAGO,MAAM,oBAAoB;AAC1B,MAAM,0BAA0B;AAGhC,MAAM,qBACX;AACK,MAAM,+BACX;AACK,MAAM,kBAAkB,CAAC,SAAiB,MAC/C,MACI,CAAC,gCAAgC,EAAE,QAAQ,oDAAoD,EAAE,KAAK,GACtG,CAAC,gCAAgC,EAAE,QAAQ,0CAA0C,CAAC;AAE5F;;CAEC,GACD,MAAM,kBAAkB,CACtB,MACA,aAA0C,CAAC,CAAC;IAE5C,IAAI,KAAK,IAAI,KAAK,UAAU,UAAU,MAAM;QAC1C,OAAO,IAAA,6OAAW,EAAC,AAAC,KAA2B,IAAI,IAAI;IACzD;IACA,IACE,KAAK,IAAI,KAAK,UACd,YAAY,QACZ,AAAC,KAAkC,MAAM,EACzC;QACA,MAAM,SAAS,AAAC,KAAiC,MAAM;QACvD,OAAO,UAAU,CAAC,OAAO,IAAI;IAC/B;IACA,+EAA+E;IAC/E,OAAO,IAAA,6OAAW,EAAC,KAAK,SAAS,CAAC;AACpC;AAEA;;CAEC,GACD,MAAM,gCAAgC,CACpC,SACA,aAA0C,CAAC,CAAC;IAE5C,qDAAqD;IACrD,MAAM,wBAAwB,QAAQ,KAAK,CAAC,MAAM,CAChD,CAAC,OAAS,KAAK,IAAI,KAAK,gBAAgB,KAAK,IAAI,KAAK;IAGxD,6BAA6B;IAC7B,MAAM,cAAc,sBAAsB,MAAM,CAC9C,CAAC,KAAK,OAAS,MAAM,gBAAgB,MAAM,aAC3C;IAGF,OAAO;AACT;AAKO,MAAM,+BAA+B,CAC1C,UACA,aAA0C,CAAC,CAAC,EAC5C,YAAoB,eAAe;IAEnC,IAAI,SAAS,MAAM,KAAK,GAAG,OAAO;IAElC,MAAM,SAAsB,EAAE;IAC9B,IAAI,cAAc;IAElB,gCAAgC;IAChC,IAAK,IAAI,IAAI,SAAS,MAAM,GAAG,GAAG,KAAK,GAAG,IAAK;QAC7C,MAAM,gBAAgB,8BACpB,QAAQ,CAAC,EAAE,EACX;QAGF,IAAI,cAAc,gBAAgB,WAAW;QAE7C,eAAe;QACf,OAAO,OAAO,CAAC,QAAQ,CAAC,EAAE;IAC5B;IAEA,OAAO;AACT;AAKO,MAAM,sBAAsB,CACjC,UACA,aAA0C,CAAC,CAAC;IAE5C,OAAO,SAAS,MAAM,CACpB,CAAC,OAAO,UACN,QAAQ,8BAA8B,SAAS,aACjD;AAEJ;AAOO,MAAM,kBAAkB,CAC7B,SACA,SAAiB,kBAAkB;IAEnC,MAAM,SAAS,IAAA,wOAAM,EAAC;IACtB,IAAI,OAAO,MAAM,IAAI,yBAAyB,OAAO;IAErD,MAAM,eAAe,IAAA,6OAAW,EAAC;IACjC,IAAI,2BAA2B,cAAc;QAC3C,OAAO,2BAA2B,IAC9B,KACA,IAAA,wOAAM,EAAC,IAAA,wOAAM,EAAC,QAAQ,KAAK,CAAC,CAAC;IACnC;IAEA,MAAM,mBAAmB,0BAA0B;IAEnD,+BAA+B;IAC/B,MAAM,aAAa,KAAK,KAAK,CAAC,mBAAmB;IACjD,MAAM,aAAa,mBAAmB;IAEtC,MAAM,aAAa,OAAO,KAAK,CAAC,GAAG;IACnC,MAAM,aAAa,OAAO,KAAK,CAAC,CAAC;IAEjC,OAAO,IAAA,wOAAM,EAAC,cAAc,SAAS,IAAA,wOAAM,EAAC;AAC9C;AAKO,MAAM,gBAAgB,CAAC,SAAiB;IAC7C,IAAI,aAAa,GAAG,OAAO;IAE3B,MAAM,SAAS,IAAA,wOAAM,EAAC;IACtB,IAAI,OAAO,MAAM,IAAI,WAAW,OAAO;IAEvC,OAAO,IAAA,wOAAM,EAAC,OAAO,KAAK,CAAC,GAAG;AAChC;AAKO,MAAM,mBAAmB,CAC9B,OACA,gBAA4C,EAAE;IAE9C,MAAM,aAAa,IAAA,6OAAW,EAAC;IAC/B,MAAM,aAAa,cAAc,MAAM,CACrC,CAAC,OAAO,OAAS,QAAQ,CAAC,KAAK,MAAM,IAAI,CAAC,GAC1C;IAEF,OAAO,aAAa;AACtB;AAKO,SAAS,eAAe,IAG9B;IACC,MAAM,EAAE,OAAO,EAAE,IAAI,EAAE,GAAG;IAC1B,MAAM,SACJ,SAAS,cAAc,+BAA+B;IACxD,OAAO,gBAAgB,SAAS;AAClC"}},
    {"offset": {"line": 176, "column": 0}, "map": {"version":3,"sources":["file:///home/runner/workspace/lib/utils/message-utils.ts"],"sourcesContent":["/**\n * Utility functions for processing message parts\n */\n\nexport interface MessagePart {\n  type: string;\n  text?: string;\n}\n\n/**\n * Extracts text content from message parts\n */\nexport const extractMessageText = (parts: MessagePart[]): string => {\n  return parts\n    .filter((part) => part.type === \"text\")\n    .map((part) => part.text || \"\")\n    .join(\"\");\n};\n\n/**\n * Checks if message parts contain any text content\n */\nexport const hasTextContent = (parts: MessagePart[]): boolean => {\n  return parts.some(\n    (part) =>\n      (part.type === \"text\" && part.text && part.text.trim() !== \"\") ||\n      part.type === \"step-start\" ||\n      part.type.startsWith(\"tool-\"),\n  );\n};\n\n/**\n * Finds the index of the last assistant message\n */\nexport const findLastAssistantMessageIndex = (\n  messages: Array<{ role: \"user\" | \"assistant\" | \"system\" }>,\n): number | undefined => {\n  return messages\n    .map((msg, index) => ({ msg, index }))\n    .reverse()\n    .find(({ msg }) => msg.role === \"assistant\")?.index;\n};\n\n/**\n * Represents a citation/source extracted from web tool outputs\n */\nexport type WebSource = {\n  title?: string;\n  url: string;\n  text?: string;\n  publishedDate?: string;\n};\n\n/**\n * Extract web sources from a message's tool outputs.\n * Handles both new `tool-web` and legacy `tool-web_search` parts\n * and flexible output shapes: array, { result: [] }, or { results: [] }.\n */\nexport const extractWebSourcesFromMessage = (message: {\n  parts?: Array<any>;\n}): Array<WebSource> => {\n  const sources: Array<WebSource> = [];\n\n  const parts: Array<any> = Array.isArray((message as any)?.parts)\n    ? (message as any).parts\n    : [];\n\n  for (const part of parts) {\n    if (part?.type === \"tool-web\" || part?.type === \"tool-web_search\") {\n      if (part.state !== \"output-available\") continue;\n      const output = part.output;\n\n      let results: any = undefined;\n      if (Array.isArray(output)) {\n        results = output;\n      } else if (Array.isArray(output?.result)) {\n        results = output.result;\n      } else if (Array.isArray(output?.results)) {\n        results = output.results;\n      }\n\n      if (Array.isArray(results)) {\n        for (const r of results) {\n          const url = r?.url || r?.id;\n          if (!url || typeof url !== \"string\") continue;\n          sources.push({\n            title: r?.title,\n            url,\n            text: r?.text,\n            publishedDate: r?.publishedDate,\n          });\n        }\n      }\n    }\n  }\n\n  return sources;\n};\n"],"names":[],"mappings":"AAAA;;CAEC;;;;;;;;;;AAUM,MAAM,qBAAqB,CAAC;IACjC,OAAO,MACJ,MAAM,CAAC,CAAC,OAAS,KAAK,IAAI,KAAK,QAC/B,GAAG,CAAC,CAAC,OAAS,KAAK,IAAI,IAAI,IAC3B,IAAI,CAAC;AACV;AAKO,MAAM,iBAAiB,CAAC;IAC7B,OAAO,MAAM,IAAI,CACf,CAAC,OACC,AAAC,KAAK,IAAI,KAAK,UAAU,KAAK,IAAI,IAAI,KAAK,IAAI,CAAC,IAAI,OAAO,MAC3D,KAAK,IAAI,KAAK,gBACd,KAAK,IAAI,CAAC,UAAU,CAAC;AAE3B;AAKO,MAAM,gCAAgC,CAC3C;IAEA,OAAO,SACJ,GAAG,CAAC,CAAC,KAAK,QAAU,CAAC;YAAE;YAAK;QAAM,CAAC,GACnC,OAAO,GACP,IAAI,CAAC,CAAC,EAAE,GAAG,EAAE,GAAK,IAAI,IAAI,KAAK,cAAc;AAClD;AAiBO,MAAM,+BAA+B,CAAC;IAG3C,MAAM,UAA4B,EAAE;IAEpC,MAAM,QAAoB,MAAM,OAAO,CAAE,SAAiB,SACtD,AAAC,QAAgB,KAAK,GACtB,EAAE;IAEN,KAAK,MAAM,QAAQ,MAAO;QACxB,IAAI,MAAM,SAAS,cAAc,MAAM,SAAS,mBAAmB;YACjE,IAAI,KAAK,KAAK,KAAK,oBAAoB;YACvC,MAAM,SAAS,KAAK,MAAM;YAE1B,IAAI,UAAe;YACnB,IAAI,MAAM,OAAO,CAAC,SAAS;gBACzB,UAAU;YACZ,OAAO,IAAI,MAAM,OAAO,CAAC,QAAQ,SAAS;gBACxC,UAAU,OAAO,MAAM;YACzB,OAAO,IAAI,MAAM,OAAO,CAAC,QAAQ,UAAU;gBACzC,UAAU,OAAO,OAAO;YAC1B;YAEA,IAAI,MAAM,OAAO,CAAC,UAAU;gBAC1B,KAAK,MAAM,KAAK,QAAS;oBACvB,MAAM,MAAM,GAAG,OAAO,GAAG;oBACzB,IAAI,CAAC,OAAO,OAAO,QAAQ,UAAU;oBACrC,QAAQ,IAAI,CAAC;wBACX,OAAO,GAAG;wBACV;wBACA,MAAM,GAAG;wBACT,eAAe,GAAG;oBACpB;gBACF;YACF;QACF;IACF;IAEA,OAAO;AACT"}},
    {"offset": {"line": 235, "column": 0}, "map": {"version":3,"sources":["file:///home/runner/workspace/lib/utils/file-utils.ts"],"sourcesContent":["import { FileMessagePart, UploadedFileState } from \"@/types/file\";\nimport { Id } from \"@/convex/_generated/dataModel\";\n\n/**\n * Upload a single file to Convex storage and return file ID and URL\n */\nexport async function uploadSingleFileToConvex(\n  file: File,\n  generateUploadUrl: () => Promise<string>,\n  saveFile: (\n    args: any,\n  ) => Promise<{ url: string; fileId: string; tokens: number }>,\n  mode: \"ask\" | \"agent\" = \"ask\",\n): Promise<{ fileId: string; url: string; tokens: number }> {\n  // Step 1: Get upload URL\n  const postUrl = await generateUploadUrl();\n\n  // Step 2: Upload file to Convex storage\n  // Use a fallback Content-Type if browser doesn't provide one (common for .md, .txt files)\n  const contentType = file.type || \"application/octet-stream\";\n  const result = await fetch(postUrl, {\n    method: \"POST\",\n    headers: { \"Content-Type\": contentType },\n    body: file,\n  });\n\n  if (!result.ok) {\n    throw new Error(`Failed to upload file ${file.name}: ${result.statusText}`);\n  }\n\n  const { storageId } = await result.json();\n\n  // Step 3: Save file metadata to database and get URL, file ID, and tokens\n  const { url, fileId, tokens } = await saveFile({\n    storageId,\n    name: file.name,\n    mediaType: contentType,\n    size: file.size,\n    mode,\n  });\n\n  return { fileId, url, tokens };\n}\n\n/**\n * Create file message part from uploaded file state (includes fileId only)\n * URLs are generated on-demand to avoid expiration issues\n */\nexport function createFileMessagePart(\n  uploadedFile: UploadedFileState,\n): FileMessagePart {\n  if (!uploadedFile.fileId) {\n    throw new Error(\"File must have fileId to create message part\");\n  }\n\n  // Use fallback for empty media types (common for .md, .txt files)\n  const mediaType = uploadedFile.file.type || \"application/octet-stream\";\n\n  return {\n    type: \"file\" as const,\n    mediaType,\n    fileId: uploadedFile.fileId,\n    name: uploadedFile.file.name,\n    size: uploadedFile.file.size,\n    // DON'T store URL - it expires! Generate on-demand via fileId\n  };\n}\n\n/**\n * Get the maximum file size allowed (in bytes)\n */\nexport function getMaxFileSize(): number {\n  return 10 * 1024 * 1024; // 10MB\n}\n\n/**\n * Validate file for upload\n */\nexport function validateFile(file: File): { valid: boolean; error?: string } {\n  if (file.size > getMaxFileSize()) {\n    return {\n      valid: false,\n      error: `File size must be less than ${getMaxFileSize() / (1024 * 1024)}MB`,\n    };\n  }\n\n  return { valid: true };\n}\n\n/**\n * Format file size for display\n */\nexport function formatFileSize(bytes: number): string {\n  if (bytes === 0) return \"0 B\";\n\n  const k = 1024;\n  const sizes = [\"B\", \"KB\", \"MB\", \"GB\"];\n  const i = Math.floor(Math.log(bytes) / Math.log(k));\n\n  return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + \" \" + sizes[i];\n}\n\n/**\n * Convert file to base64 data URL for preview\n */\nexport function fileToBase64(file: File): Promise<string> {\n  return new Promise((resolve, reject) => {\n    const reader = new FileReader();\n    reader.onload = () => resolve(reader.result as string);\n    reader.onerror = reject;\n    reader.readAsDataURL(file);\n  });\n}\n\n/**\n * Check if file is an image that can be previewed\n */\nexport function isImageFile(file: File): boolean {\n  return file.type.startsWith(\"image/\");\n}\n\n/**\n * Check if media type is a supported image format for AI\n * AI supports: PNG, JPEG, WEBP, and non-animated GIF\n */\nexport function isSupportedImageMediaType(mediaType: string): boolean {\n  const supportedTypes = [\n    \"image/png\",\n    \"image/jpeg\",\n    \"image/jpg\",\n    \"image/webp\",\n    \"image/gif\",\n  ];\n  return supportedTypes.includes(mediaType.toLowerCase());\n}\n\n/**\n * Maximum number of files allowed to be uploaded at once\n */\nexport const MAX_FILES_LIMIT = 5;\n\n/**\n * Helper to create file message part from uploadedFile that has both fileId and URL\n */\nexport function createFileMessagePartFromUploadedFile(\n  uploadedFile: UploadedFileState,\n): FileMessagePart | null {\n  if (!uploadedFile.fileId || !uploadedFile.uploaded) {\n    return null;\n  }\n\n  return {\n    type: \"file\" as const,\n    mediaType: uploadedFile.file.type,\n    fileId: uploadedFile.fileId,\n    name: uploadedFile.file.name,\n    size: uploadedFile.file.size,\n    // DON'T store URL - it expires! Generate on-demand via fileId\n    // url: uploadedFile.url,\n  };\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;AAMO,eAAe,yBACpB,IAAU,EACV,iBAAwC,EACxC,QAE6D,EAC7D,OAAwB,KAAK;IAE7B,yBAAyB;IACzB,MAAM,UAAU,MAAM;IAEtB,wCAAwC;IACxC,0FAA0F;IAC1F,MAAM,cAAc,KAAK,IAAI,IAAI;IACjC,MAAM,SAAS,MAAM,MAAM,SAAS;QAClC,QAAQ;QACR,SAAS;YAAE,gBAAgB;QAAY;QACvC,MAAM;IACR;IAEA,IAAI,CAAC,OAAO,EAAE,EAAE;QACd,MAAM,IAAI,MAAM,CAAC,sBAAsB,EAAE,KAAK,IAAI,CAAC,EAAE,EAAE,OAAO,UAAU,EAAE;IAC5E;IAEA,MAAM,EAAE,SAAS,EAAE,GAAG,MAAM,OAAO,IAAI;IAEvC,0EAA0E;IAC1E,MAAM,EAAE,GAAG,EAAE,MAAM,EAAE,MAAM,EAAE,GAAG,MAAM,SAAS;QAC7C;QACA,MAAM,KAAK,IAAI;QACf,WAAW;QACX,MAAM,KAAK,IAAI;QACf;IACF;IAEA,OAAO;QAAE;QAAQ;QAAK;IAAO;AAC/B;AAMO,SAAS,sBACd,YAA+B;IAE/B,IAAI,CAAC,aAAa,MAAM,EAAE;QACxB,MAAM,IAAI,MAAM;IAClB;IAEA,kEAAkE;IAClE,MAAM,YAAY,aAAa,IAAI,CAAC,IAAI,IAAI;IAE5C,OAAO;QACL,MAAM;QACN;QACA,QAAQ,aAAa,MAAM;QAC3B,MAAM,aAAa,IAAI,CAAC,IAAI;QAC5B,MAAM,aAAa,IAAI,CAAC,IAAI;IAE9B;AACF;AAKO,SAAS;IACd,OAAO,KAAK,OAAO,MAAM,OAAO;AAClC;AAKO,SAAS,aAAa,IAAU;IACrC,IAAI,KAAK,IAAI,GAAG,kBAAkB;QAChC,OAAO;YACL,OAAO;YACP,OAAO,CAAC,4BAA4B,EAAE,mBAAmB,CAAC,OAAO,IAAI,EAAE,EAAE,CAAC;QAC5E;IACF;IAEA,OAAO;QAAE,OAAO;IAAK;AACvB;AAKO,SAAS,eAAe,KAAa;IAC1C,IAAI,UAAU,GAAG,OAAO;IAExB,MAAM,IAAI;IACV,MAAM,QAAQ;QAAC;QAAK;QAAM;QAAM;KAAK;IACrC,MAAM,IAAI,KAAK,KAAK,CAAC,KAAK,GAAG,CAAC,SAAS,KAAK,GAAG,CAAC;IAEhD,OAAO,WAAW,CAAC,QAAQ,KAAK,GAAG,CAAC,GAAG,EAAE,EAAE,OAAO,CAAC,MAAM,MAAM,KAAK,CAAC,EAAE;AACzE;AAKO,SAAS,aAAa,IAAU;IACrC,OAAO,IAAI,QAAQ,CAAC,SAAS;QAC3B,MAAM,SAAS,IAAI;QACnB,OAAO,MAAM,GAAG,IAAM,QAAQ,OAAO,MAAM;QAC3C,OAAO,OAAO,GAAG;QACjB,OAAO,aAAa,CAAC;IACvB;AACF;AAKO,SAAS,YAAY,IAAU;IACpC,OAAO,KAAK,IAAI,CAAC,UAAU,CAAC;AAC9B;AAMO,SAAS,0BAA0B,SAAiB;IACzD,MAAM,iBAAiB;QACrB;QACA;QACA;QACA;QACA;KACD;IACD,OAAO,eAAe,QAAQ,CAAC,UAAU,WAAW;AACtD;AAKO,MAAM,kBAAkB;AAKxB,SAAS,sCACd,YAA+B;IAE/B,IAAI,CAAC,aAAa,MAAM,IAAI,CAAC,aAAa,QAAQ,EAAE;QAClD,OAAO;IACT;IAEA,OAAO;QACL,MAAM;QACN,WAAW,aAAa,IAAI,CAAC,IAAI;QACjC,QAAQ,aAAa,MAAM;QAC3B,MAAM,aAAa,IAAI,CAAC,IAAI;QAC5B,MAAM,aAAa,IAAI,CAAC,IAAI;IAG9B;AACF"}},
    {"offset": {"line": 366, "column": 0}, "map": {"version":3,"sources":["file:///home/runner/workspace/lib/utils/sidebar-utils.ts"],"sourcesContent":["import { SidebarContent, SidebarFile } from \"@/types/chat\";\n\ninterface MessagePart {\n  type: string;\n  toolCallId?: string;\n  input?: any;\n  output?: any;\n  state?: string;\n  [key: string]: any;\n}\n\nexport interface Message {\n  role: string;\n  parts?: MessagePart[];\n  [key: string]: any;\n}\n\nexport function extractAllSidebarContent(\n  messages: Message[],\n): SidebarContent[] {\n  const contentList: SidebarContent[] = [];\n\n  messages.forEach((message) => {\n    if (message.role !== \"assistant\" || !message.parts) return;\n\n    // Collect terminal output from data-terminal parts (for streaming)\n    const terminalDataMap = new Map<string, string>();\n    // Collect Python output from data-python parts (for streaming)\n    const pythonDataMap = new Map<string, string>();\n    // Collect diff data from data-diff parts (for search_replace UI-only diff display)\n    const diffDataMap = new Map<\n      string,\n      { originalContent: string; modifiedContent: string }\n    >();\n\n    message.parts.forEach((part) => {\n      if (part.type === \"data-terminal\" && part.data?.toolCallId) {\n        const toolCallId = part.data.toolCallId;\n        const terminalOutput = part.data?.terminal || \"\";\n        const existing = terminalDataMap.get(toolCallId) || \"\";\n        terminalDataMap.set(toolCallId, existing + terminalOutput);\n      }\n      if (part.type === \"data-python\" && part.data?.toolCallId) {\n        const toolCallId = part.data.toolCallId;\n        const pythonOutput = part.data?.terminal || \"\"; // Python uses same 'terminal' field\n        const existing = pythonDataMap.get(toolCallId) || \"\";\n        pythonDataMap.set(toolCallId, existing + pythonOutput);\n      }\n      if (part.type === \"data-diff\" && part.data?.toolCallId) {\n        const toolCallId = part.data.toolCallId;\n        diffDataMap.set(toolCallId, {\n          originalContent: part.data.originalContent || \"\",\n          modifiedContent: part.data.modifiedContent || \"\",\n        });\n      }\n    });\n\n    message.parts.forEach((part) => {\n      // Terminal\n      if (part.type === \"tool-run_terminal_cmd\" && part.input?.command) {\n        const command = part.input.command;\n\n        // Get streaming output from data-terminal parts\n        const streamingOutput =\n          terminalDataMap.get(part.toolCallId || \"\") || \"\";\n\n        // Extract output from result object (handles both new and legacy formats)\n        const result = part.output?.result;\n        let output = \"\";\n\n        if (result) {\n          // New format: result.output\n          if (typeof result.output === \"string\") {\n            output = result.output;\n          }\n          // Legacy format: result.stdout + result.stderr\n          else if (result.stdout !== undefined || result.stderr !== undefined) {\n            output = (result.stdout || \"\") + (result.stderr || \"\");\n          }\n          // If result is a string directly (fallback)\n          else if (typeof result === \"string\") {\n            output = result;\n          }\n        }\n\n        // Fallback to streaming output or direct output property\n        const finalOutput =\n          output || streamingOutput || part.output?.output || \"\";\n\n        contentList.push({\n          command,\n          output: finalOutput,\n          isExecuting:\n            part.state === \"input-available\" || part.state === \"running\",\n          isBackground: part.input.is_background,\n          toolCallId: part.toolCallId || \"\",\n        });\n      }\n\n      // Python\n      if (part.type === \"tool-python\" && part.input?.code) {\n        const code = part.input.code;\n\n        // Get streaming output from data-python parts\n        const streamingOutput = pythonDataMap.get(part.toolCallId || \"\") || \"\";\n\n        const result = part.output?.result;\n        let output = \"\";\n\n        if (result) {\n          // New format: result.output\n          if (typeof result.output === \"string\") {\n            output = result.output;\n          }\n          // Legacy format: result.stdout + result.stderr\n          else if (result.stdout !== undefined || result.stderr !== undefined) {\n            output = (result.stdout || \"\") + (result.stderr || \"\");\n          }\n          // If result is a string directly (fallback)\n          else if (typeof result === \"string\") {\n            output = result;\n          }\n        }\n\n        const finalOutput =\n          output || streamingOutput || part.output?.output || \"\";\n\n        contentList.push({\n          code,\n          output: finalOutput,\n          isExecuting:\n            part.state === \"input-available\" || part.state === \"running\",\n          toolCallId: part.toolCallId || \"\",\n        });\n      }\n\n      // File Operations - only extract when output is available\n      // This ensures content is ready when auto-following\n      if (\n        (part.type === \"tool-read_file\" ||\n          part.type === \"tool-write_file\" ||\n          part.type === \"tool-search_replace\" ||\n          part.type === \"tool-multi_edit\") &&\n        part.state === \"output-available\"\n      ) {\n        const fileInput = part.input;\n        if (!fileInput) return;\n\n        const filePath =\n          fileInput.file_path || fileInput.path || fileInput.target_file || \"\";\n        if (!filePath) return;\n\n        let action: SidebarFile[\"action\"] = \"reading\";\n        let content = \"\";\n        let range = undefined;\n\n        if (part.type === \"tool-read_file\") {\n          action = \"reading\";\n          // Extract result - handle both string and object formats\n          const result = part.output?.result;\n          let rawContent = \"\";\n\n          if (typeof result === \"string\") {\n            rawContent = result;\n          } else if (result && typeof result === \"object\") {\n            // If result is an object, try to extract content\n            rawContent = result.content || result.text || result.result || \"\";\n          }\n\n          // Clean line numbers from read output (only if we have content)\n          if (rawContent) {\n            content = rawContent.replace(/^\\s*\\d+\\|/gm, \"\");\n          }\n\n          if (fileInput.offset && fileInput.limit) {\n            range = {\n              start: fileInput.offset,\n              end: fileInput.offset + fileInput.limit - 1,\n            };\n          }\n        } else if (part.type === \"tool-write_file\") {\n          action = \"writing\";\n          content = fileInput.contents || fileInput.content || \"\";\n        } else if (\n          part.type === \"tool-search_replace\" ||\n          part.type === \"tool-multi_edit\"\n        ) {\n          action = \"editing\";\n          // Extract result - handle both string and object formats\n          const result = part.output?.result;\n          if (typeof result === \"string\") {\n            content = result;\n          } else if (result && typeof result === \"object\") {\n            content = result.content || result.text || result.result || \"\";\n          } else {\n            content = \"\";\n          }\n        }\n\n        // For search_replace, try to get diff data from data-diff parts (not persisted across reloads)\n        let originalContent: string | undefined;\n        let modifiedContent: string | undefined;\n\n        if (part.type === \"tool-search_replace\" && part.toolCallId) {\n          const streamedDiff = diffDataMap.get(part.toolCallId);\n          if (streamedDiff) {\n            originalContent = streamedDiff.originalContent;\n            modifiedContent = streamedDiff.modifiedContent;\n          }\n        }\n\n        contentList.push({\n          path: filePath,\n          content: modifiedContent || content,\n          range,\n          action,\n          toolCallId: part.toolCallId || \"\",\n          originalContent,\n          modifiedContent,\n        });\n      }\n    });\n  });\n\n  return contentList;\n}\n"],"names":[],"mappings":";;;;AAiBO,SAAS,yBACd,QAAmB;IAEnB,MAAM,cAAgC,EAAE;IAExC,SAAS,OAAO,CAAC,CAAC;QAChB,IAAI,QAAQ,IAAI,KAAK,eAAe,CAAC,QAAQ,KAAK,EAAE;QAEpD,mEAAmE;QACnE,MAAM,kBAAkB,IAAI;QAC5B,+DAA+D;QAC/D,MAAM,gBAAgB,IAAI;QAC1B,mFAAmF;QACnF,MAAM,cAAc,IAAI;QAKxB,QAAQ,KAAK,CAAC,OAAO,CAAC,CAAC;YACrB,IAAI,KAAK,IAAI,KAAK,mBAAmB,KAAK,IAAI,EAAE,YAAY;gBAC1D,MAAM,aAAa,KAAK,IAAI,CAAC,UAAU;gBACvC,MAAM,iBAAiB,KAAK,IAAI,EAAE,YAAY;gBAC9C,MAAM,WAAW,gBAAgB,GAAG,CAAC,eAAe;gBACpD,gBAAgB,GAAG,CAAC,YAAY,WAAW;YAC7C;YACA,IAAI,KAAK,IAAI,KAAK,iBAAiB,KAAK,IAAI,EAAE,YAAY;gBACxD,MAAM,aAAa,KAAK,IAAI,CAAC,UAAU;gBACvC,MAAM,eAAe,KAAK,IAAI,EAAE,YAAY,IAAI,oCAAoC;gBACpF,MAAM,WAAW,cAAc,GAAG,CAAC,eAAe;gBAClD,cAAc,GAAG,CAAC,YAAY,WAAW;YAC3C;YACA,IAAI,KAAK,IAAI,KAAK,eAAe,KAAK,IAAI,EAAE,YAAY;gBACtD,MAAM,aAAa,KAAK,IAAI,CAAC,UAAU;gBACvC,YAAY,GAAG,CAAC,YAAY;oBAC1B,iBAAiB,KAAK,IAAI,CAAC,eAAe,IAAI;oBAC9C,iBAAiB,KAAK,IAAI,CAAC,eAAe,IAAI;gBAChD;YACF;QACF;QAEA,QAAQ,KAAK,CAAC,OAAO,CAAC,CAAC;YACrB,WAAW;YACX,IAAI,KAAK,IAAI,KAAK,2BAA2B,KAAK,KAAK,EAAE,SAAS;gBAChE,MAAM,UAAU,KAAK,KAAK,CAAC,OAAO;gBAElC,gDAAgD;gBAChD,MAAM,kBACJ,gBAAgB,GAAG,CAAC,KAAK,UAAU,IAAI,OAAO;gBAEhD,0EAA0E;gBAC1E,MAAM,SAAS,KAAK,MAAM,EAAE;gBAC5B,IAAI,SAAS;gBAEb,IAAI,QAAQ;oBACV,4BAA4B;oBAC5B,IAAI,OAAO,OAAO,MAAM,KAAK,UAAU;wBACrC,SAAS,OAAO,MAAM;oBACxB,OAEK,IAAI,OAAO,MAAM,KAAK,aAAa,OAAO,MAAM,KAAK,WAAW;wBACnE,SAAS,CAAC,OAAO,MAAM,IAAI,EAAE,IAAI,CAAC,OAAO,MAAM,IAAI,EAAE;oBACvD,OAEK,IAAI,OAAO,WAAW,UAAU;wBACnC,SAAS;oBACX;gBACF;gBAEA,yDAAyD;gBACzD,MAAM,cACJ,UAAU,mBAAmB,KAAK,MAAM,EAAE,UAAU;gBAEtD,YAAY,IAAI,CAAC;oBACf;oBACA,QAAQ;oBACR,aACE,KAAK,KAAK,KAAK,qBAAqB,KAAK,KAAK,KAAK;oBACrD,cAAc,KAAK,KAAK,CAAC,aAAa;oBACtC,YAAY,KAAK,UAAU,IAAI;gBACjC;YACF;YAEA,SAAS;YACT,IAAI,KAAK,IAAI,KAAK,iBAAiB,KAAK,KAAK,EAAE,MAAM;gBACnD,MAAM,OAAO,KAAK,KAAK,CAAC,IAAI;gBAE5B,8CAA8C;gBAC9C,MAAM,kBAAkB,cAAc,GAAG,CAAC,KAAK,UAAU,IAAI,OAAO;gBAEpE,MAAM,SAAS,KAAK,MAAM,EAAE;gBAC5B,IAAI,SAAS;gBAEb,IAAI,QAAQ;oBACV,4BAA4B;oBAC5B,IAAI,OAAO,OAAO,MAAM,KAAK,UAAU;wBACrC,SAAS,OAAO,MAAM;oBACxB,OAEK,IAAI,OAAO,MAAM,KAAK,aAAa,OAAO,MAAM,KAAK,WAAW;wBACnE,SAAS,CAAC,OAAO,MAAM,IAAI,EAAE,IAAI,CAAC,OAAO,MAAM,IAAI,EAAE;oBACvD,OAEK,IAAI,OAAO,WAAW,UAAU;wBACnC,SAAS;oBACX;gBACF;gBAEA,MAAM,cACJ,UAAU,mBAAmB,KAAK,MAAM,EAAE,UAAU;gBAEtD,YAAY,IAAI,CAAC;oBACf;oBACA,QAAQ;oBACR,aACE,KAAK,KAAK,KAAK,qBAAqB,KAAK,KAAK,KAAK;oBACrD,YAAY,KAAK,UAAU,IAAI;gBACjC;YACF;YAEA,0DAA0D;YAC1D,oDAAoD;YACpD,IACE,CAAC,KAAK,IAAI,KAAK,oBACb,KAAK,IAAI,KAAK,qBACd,KAAK,IAAI,KAAK,yBACd,KAAK,IAAI,KAAK,iBAAiB,KACjC,KAAK,KAAK,KAAK,oBACf;gBACA,MAAM,YAAY,KAAK,KAAK;gBAC5B,IAAI,CAAC,WAAW;gBAEhB,MAAM,WACJ,UAAU,SAAS,IAAI,UAAU,IAAI,IAAI,UAAU,WAAW,IAAI;gBACpE,IAAI,CAAC,UAAU;gBAEf,IAAI,SAAgC;gBACpC,IAAI,UAAU;gBACd,IAAI,QAAQ;gBAEZ,IAAI,KAAK,IAAI,KAAK,kBAAkB;oBAClC,SAAS;oBACT,yDAAyD;oBACzD,MAAM,SAAS,KAAK,MAAM,EAAE;oBAC5B,IAAI,aAAa;oBAEjB,IAAI,OAAO,WAAW,UAAU;wBAC9B,aAAa;oBACf,OAAO,IAAI,UAAU,OAAO,WAAW,UAAU;wBAC/C,iDAAiD;wBACjD,aAAa,OAAO,OAAO,IAAI,OAAO,IAAI,IAAI,OAAO,MAAM,IAAI;oBACjE;oBAEA,gEAAgE;oBAChE,IAAI,YAAY;wBACd,UAAU,WAAW,OAAO,CAAC,eAAe;oBAC9C;oBAEA,IAAI,UAAU,MAAM,IAAI,UAAU,KAAK,EAAE;wBACvC,QAAQ;4BACN,OAAO,UAAU,MAAM;4BACvB,KAAK,UAAU,MAAM,GAAG,UAAU,KAAK,GAAG;wBAC5C;oBACF;gBACF,OAAO,IAAI,KAAK,IAAI,KAAK,mBAAmB;oBAC1C,SAAS;oBACT,UAAU,UAAU,QAAQ,IAAI,UAAU,OAAO,IAAI;gBACvD,OAAO,IACL,KAAK,IAAI,KAAK,yBACd,KAAK,IAAI,KAAK,mBACd;oBACA,SAAS;oBACT,yDAAyD;oBACzD,MAAM,SAAS,KAAK,MAAM,EAAE;oBAC5B,IAAI,OAAO,WAAW,UAAU;wBAC9B,UAAU;oBACZ,OAAO,IAAI,UAAU,OAAO,WAAW,UAAU;wBAC/C,UAAU,OAAO,OAAO,IAAI,OAAO,IAAI,IAAI,OAAO,MAAM,IAAI;oBAC9D,OAAO;wBACL,UAAU;oBACZ;gBACF;gBAEA,+FAA+F;gBAC/F,IAAI;gBACJ,IAAI;gBAEJ,IAAI,KAAK,IAAI,KAAK,yBAAyB,KAAK,UAAU,EAAE;oBAC1D,MAAM,eAAe,YAAY,GAAG,CAAC,KAAK,UAAU;oBACpD,IAAI,cAAc;wBAChB,kBAAkB,aAAa,eAAe;wBAC9C,kBAAkB,aAAa,eAAe;oBAChD;gBACF;gBAEA,YAAY,IAAI,CAAC;oBACf,MAAM;oBACN,SAAS,mBAAmB;oBAC5B;oBACA;oBACA,YAAY,KAAK,UAAU,IAAI;oBAC/B;oBACA;gBACF;YACF;QACF;IACF;IAEA,OAAO;AACT"}},
    {"offset": {"line": 529, "column": 0}, "map": {"version":3,"sources":["file:///home/runner/workspace/lib/pricing/features.ts"],"sourcesContent":["import type React from \"react\";\nimport {\n  Sparkle,\n  MessagesSquare,\n  Brain,\n  Clock,\n  Upload,\n  FlaskConical,\n  SquareTerminal,\n  CreditCard,\n  Users,\n  Code,\n} from \"lucide-react\";\n\nexport type PricingFeature = {\n  icon: React.ComponentType<{ className?: string }>;\n  text: string;\n};\n\nexport const freeFeatures: Array<PricingFeature> = [\n  { icon: Sparkle, text: \"Access to basic AI model\" },\n  { icon: Clock, text: \"Limited and slower responses\" },\n  { icon: Brain, text: \"Basic memory and context\" },\n];\n\nexport const proFeatures: Array<PricingFeature> = [\n  { icon: Sparkle, text: \"Access to smartest AI model\" },\n  { icon: MessagesSquare, text: \"Expanded messaging\" },\n  { icon: Upload, text: \"Access to file uploads\" },\n  { icon: SquareTerminal, text: \"Agent mode with terminal\" },\n  { icon: Brain, text: \"Expanded memory and context\" },\n];\n\nexport const ultraFeatures: Array<PricingFeature> = [\n  { icon: MessagesSquare, text: \"Unlimited messages and uploads\" },\n  { icon: Brain, text: \"Maximum memory and context\" },\n  { icon: SquareTerminal, text: \"Expanded Agent mode\" },\n  { icon: FlaskConical, text: \"Research preview of new features\" },\n];\n\nexport const teamFeatures: Array<PricingFeature> = [\n  {\n    icon: Sparkle,\n    text: \"Everything in Pro and more: access to smartest AI model, expanded messaging, file uploads, agent mode with terminal, expanded memory and context\",\n  },\n  { icon: CreditCard, text: \"Centralized billing and invoicing\" },\n  { icon: Users, text: \"Advanced team + seat management\" },\n];\n"],"names":[],"mappings":";;;;;;;;;;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAkBO,MAAM,eAAsC;IACjD;QAAE,MAAM,uSAAO;QAAE,MAAM;IAA2B;IAClD;QAAE,MAAM,iSAAK;QAAE,MAAM;IAA+B;IACpD;QAAE,MAAM,iSAAK;QAAE,MAAM;IAA2B;CACjD;AAEM,MAAM,cAAqC;IAChD;QAAE,MAAM,uSAAO;QAAE,MAAM;IAA8B;IACrD;QAAE,MAAM,gUAAc;QAAE,MAAM;IAAqB;IACnD;QAAE,MAAM,oSAAM;QAAE,MAAM;IAAyB;IAC/C;QAAE,MAAM,gUAAc;QAAE,MAAM;IAA2B;IACzD;QAAE,MAAM,iSAAK;QAAE,MAAM;IAA8B;CACpD;AAEM,MAAM,gBAAuC;IAClD;QAAE,MAAM,gUAAc;QAAE,MAAM;IAAiC;IAC/D;QAAE,MAAM,iSAAK;QAAE,MAAM;IAA6B;IAClD;QAAE,MAAM,gUAAc;QAAE,MAAM;IAAsB;IACpD;QAAE,MAAM,0TAAY;QAAE,MAAM;IAAmC;CAChE;AAEM,MAAM,eAAsC;IACjD;QACE,MAAM,uSAAO;QACb,MAAM;IACR;IACA;QAAE,MAAM,oTAAU;QAAE,MAAM;IAAoC;IAC9D;QAAE,MAAM,iSAAK;QAAE,MAAM;IAAkC;CACxD"}},
    {"offset": {"line": 621, "column": 0}, "map": {"version":3,"sources":["file:///home/runner/workspace/lib/utils/logout.ts"],"sourcesContent":["\"use client\";\n\nimport { clearAllDrafts } from \"@/lib/utils/client-storage\";\n\nexport const clientLogout = (redirectPath: string = \"/logout\"): void => {\n  if (typeof window === \"undefined\") return;\n  try {\n    clearAllDrafts();\n  } catch {\n    // ignore\n  } finally {\n    try {\n      window.location.href = redirectPath;\n    } catch {\n      // ignore\n    }\n  }\n};\n"],"names":[],"mappings":";;;;AAEA;AAFA;;AAIO,MAAM,eAAe,CAAC,eAAuB,SAAS;IAC3D,wCAAmC;;;AAYrC"}},
    {"offset": {"line": 637, "column": 0}, "map": {"version":3,"sources":["file:///home/runner/workspace/lib/utils/message-processor.ts"],"sourcesContent":["import { ChatMessage } from \"@/types/chat\";\n\n// Generic interface for all tool parts\ninterface BaseToolPart {\n  type: string;\n  toolCallId: string;\n  state: \"input-streaming\" | \"input-available\" | \"output-available\";\n  input?: any;\n  output?: any;\n}\n\n// Specific interface for terminal tools that have special data handling\ninterface TerminalToolPart extends BaseToolPart {\n  type: \"tool-run_terminal_cmd\";\n  input?: {\n    command: string;\n    explanation: string;\n    is_background: boolean;\n  };\n  output?: {\n    result: {\n      exitCode: number;\n      stdout?: string;\n      stderr?: string;\n      error?: string;\n    };\n  };\n}\n\n// Interface for data parts that need to be collected\ninterface DataPart {\n  type: string;\n  data?: {\n    toolCallId: string;\n    [key: string]: any;\n  };\n}\n\n/**\n * Normalizes chat messages by transforming incomplete tool calls and cleaning up data parts.\n * Also prepares the last user message for backend sending.\n *\n * This function:\n * 1. Collects terminal output from data-terminal parts (only terminal tools use data streaming)\n * 2. Transforms tools with input-available state to output-available state when interrupted\n * 3. Removes data-terminal parts to clean up the message structure\n * 4. Prepares the last user message for backend to reduce payload size\n *\n * Performance optimization: Early exits if no assistant messages or no changes needed\n *\n * @param messages - Array of UI messages to normalize\n * @returns Object with normalized messages, last message array, and hasChanges flag\n */\nexport const normalizeMessages = (\n  messages: ChatMessage[],\n): {\n  messages: ChatMessage[];\n  lastMessage: ChatMessage[];\n  hasChanges: boolean;\n} => {\n  // Early return for empty messages\n  if (!messages || messages.length === 0) {\n    return { messages: [], lastMessage: [], hasChanges: false };\n  }\n\n  // Quick check: if no assistant messages, skip processing\n  const hasAssistantMessages = messages.some((m) => m.role === \"assistant\");\n  if (!hasAssistantMessages) {\n    const lastUserMessage = messages\n      .slice()\n      .reverse()\n      .find((msg) => msg.role === \"user\");\n    return {\n      messages,\n      lastMessage: lastUserMessage ? [lastUserMessage] : [],\n      hasChanges: false,\n    };\n  }\n\n  let hasChanges = false;\n  const normalizedMessages = messages.map((message) => {\n    // Only process assistant messages\n    if (message.role !== \"assistant\" || !message.parts) {\n      return message;\n    }\n\n    const processedParts: any[] = [];\n    let messageChanged = false;\n\n    // Collect terminal output from data-terminal parts (only terminal tools use data streaming)\n    const terminalDataMap = new Map<string, string>();\n\n    message.parts.forEach((part: any) => {\n      const dataPart = part as DataPart;\n\n      // Only handle data-terminal parts (other tools don't use data streaming)\n      if (dataPart.type === \"data-terminal\" && dataPart.data?.toolCallId) {\n        const toolCallId = dataPart.data.toolCallId;\n        const terminalOutput = dataPart.data.terminal || \"\";\n\n        // Accumulate terminal output for each toolCallId\n        const existing = terminalDataMap.get(toolCallId) || \"\";\n        terminalDataMap.set(toolCallId, existing + terminalOutput);\n        messageChanged = true; // Data-terminal parts will be removed\n      }\n    });\n\n    // Process each part, transform incomplete tools, and filter out data-terminal parts\n    message.parts.forEach((part: any) => {\n      const toolPart = part as BaseToolPart;\n\n      // Skip data-terminal parts - we've already collected their data\n      if (toolPart.type === \"data-terminal\") {\n        messageChanged = true; // Part is being removed\n        return;\n      }\n\n      // Check if this is a tool part that needs transformation\n      if (toolPart.type?.startsWith(\"tool-\")) {\n        if (toolPart.state === \"input-available\") {\n          // Transform incomplete tools to completed state\n          const transformedPart = transformIncompleteToolPart(\n            toolPart,\n            terminalDataMap,\n          );\n          processedParts.push(transformedPart);\n          messageChanged = true; // Part is being transformed\n        } else if (toolPart.state === \"input-streaming\") {\n          // Transform streaming tools to completed state (they were interrupted)\n          const transformedPart = transformIncompleteToolPart(\n            { ...toolPart, state: \"input-available\" },\n            terminalDataMap,\n          );\n          processedParts.push(transformedPart);\n          messageChanged = true; // Part is being transformed\n        } else {\n          // Keep completed tools unchanged\n          processedParts.push(part);\n        }\n      } else {\n        // Keep non-tool parts unchanged\n        processedParts.push(part);\n      }\n    });\n\n    if (messageChanged) {\n      hasChanges = true;\n    }\n\n    return messageChanged\n      ? {\n          ...message,\n          parts: processedParts,\n        }\n      : message;\n  });\n\n  // Prepare last message array with only the last user message\n  const lastUserMessage = normalizedMessages\n    .slice()\n    .reverse()\n    .find((msg) => msg.role === \"user\");\n\n  const lastMessage = lastUserMessage ? [lastUserMessage] : [];\n\n  return { messages: normalizedMessages, lastMessage, hasChanges };\n};\n\n/**\n * Transforms an incomplete tool part (input-available state) to a complete one (output-available state)\n * using collected terminal data for terminal tools.\n */\nconst transformIncompleteToolPart = (\n  toolPart: BaseToolPart,\n  terminalDataMap: Map<string, string>,\n): BaseToolPart => {\n  // Handle terminal tools with special terminal output handling\n  if (toolPart.type === \"tool-run_terminal_cmd\") {\n    return transformTerminalToolPart(\n      toolPart as TerminalToolPart,\n      terminalDataMap,\n    );\n  }\n\n  // Handle all other tools generically (they don't have data streaming)\n  return transformGenericToolPart(toolPart);\n};\n\n/**\n * Transforms terminal tool parts with special handling for terminal output\n */\nconst transformTerminalToolPart = (\n  terminalPart: TerminalToolPart,\n  terminalDataMap: Map<string, string>,\n): TerminalToolPart => {\n  const stdout = terminalDataMap.get(terminalPart.toolCallId) || \"\";\n\n  return {\n    type: \"tool-run_terminal_cmd\",\n    toolCallId: terminalPart.toolCallId,\n    state: \"output-available\",\n    input: terminalPart.input,\n    output: {\n      result: {\n        exitCode: 130, // Standard exit code for SIGINT (interrupted)\n        stdout: stdout,\n        stderr:\n          stdout.length === 0 ? \"Command was stopped/aborted by user\" : \"\",\n      },\n    },\n  };\n};\n\n/**\n * Generic transformation for all non-terminal tool types\n */\nconst transformGenericToolPart = (toolPart: BaseToolPart): BaseToolPart => {\n  // Handle specific tool types with appropriate default outputs\n  switch (toolPart.type) {\n    case \"tool-todo_write\":\n      return {\n        ...toolPart,\n        state: \"output-available\",\n        output: {\n          result: \"Todo operation was interrupted by user\",\n          counts: { completed: 0, total: 0 },\n          currentTodos: [],\n        },\n      };\n\n    default:\n      // Generic transformation for file tools and unknown tool types\n      return {\n        ...toolPart,\n        state: \"output-available\",\n        output: {\n          result: \"Operation was interrupted by user\",\n        },\n      };\n  }\n};\n"],"names":[],"mappings":";;;;AAqDO,MAAM,oBAAoB,CAC/B;IAMA,kCAAkC;IAClC,IAAI,CAAC,YAAY,SAAS,MAAM,KAAK,GAAG;QACtC,OAAO;YAAE,UAAU,EAAE;YAAE,aAAa,EAAE;YAAE,YAAY;QAAM;IAC5D;IAEA,yDAAyD;IACzD,MAAM,uBAAuB,SAAS,IAAI,CAAC,CAAC,IAAM,EAAE,IAAI,KAAK;IAC7D,IAAI,CAAC,sBAAsB;QACzB,MAAM,kBAAkB,SACrB,KAAK,GACL,OAAO,GACP,IAAI,CAAC,CAAC,MAAQ,IAAI,IAAI,KAAK;QAC9B,OAAO;YACL;YACA,aAAa,kBAAkB;gBAAC;aAAgB,GAAG,EAAE;YACrD,YAAY;QACd;IACF;IAEA,IAAI,aAAa;IACjB,MAAM,qBAAqB,SAAS,GAAG,CAAC,CAAC;QACvC,kCAAkC;QAClC,IAAI,QAAQ,IAAI,KAAK,eAAe,CAAC,QAAQ,KAAK,EAAE;YAClD,OAAO;QACT;QAEA,MAAM,iBAAwB,EAAE;QAChC,IAAI,iBAAiB;QAErB,4FAA4F;QAC5F,MAAM,kBAAkB,IAAI;QAE5B,QAAQ,KAAK,CAAC,OAAO,CAAC,CAAC;YACrB,MAAM,WAAW;YAEjB,yEAAyE;YACzE,IAAI,SAAS,IAAI,KAAK,mBAAmB,SAAS,IAAI,EAAE,YAAY;gBAClE,MAAM,aAAa,SAAS,IAAI,CAAC,UAAU;gBAC3C,MAAM,iBAAiB,SAAS,IAAI,CAAC,QAAQ,IAAI;gBAEjD,iDAAiD;gBACjD,MAAM,WAAW,gBAAgB,GAAG,CAAC,eAAe;gBACpD,gBAAgB,GAAG,CAAC,YAAY,WAAW;gBAC3C,iBAAiB,MAAM,sCAAsC;YAC/D;QACF;QAEA,oFAAoF;QACpF,QAAQ,KAAK,CAAC,OAAO,CAAC,CAAC;YACrB,MAAM,WAAW;YAEjB,gEAAgE;YAChE,IAAI,SAAS,IAAI,KAAK,iBAAiB;gBACrC,iBAAiB,MAAM,wBAAwB;gBAC/C;YACF;YAEA,yDAAyD;YACzD,IAAI,SAAS,IAAI,EAAE,WAAW,UAAU;gBACtC,IAAI,SAAS,KAAK,KAAK,mBAAmB;oBACxC,gDAAgD;oBAChD,MAAM,kBAAkB,4BACtB,UACA;oBAEF,eAAe,IAAI,CAAC;oBACpB,iBAAiB,MAAM,4BAA4B;gBACrD,OAAO,IAAI,SAAS,KAAK,KAAK,mBAAmB;oBAC/C,uEAAuE;oBACvE,MAAM,kBAAkB,4BACtB;wBAAE,GAAG,QAAQ;wBAAE,OAAO;oBAAkB,GACxC;oBAEF,eAAe,IAAI,CAAC;oBACpB,iBAAiB,MAAM,4BAA4B;gBACrD,OAAO;oBACL,iCAAiC;oBACjC,eAAe,IAAI,CAAC;gBACtB;YACF,OAAO;gBACL,gCAAgC;gBAChC,eAAe,IAAI,CAAC;YACtB;QACF;QAEA,IAAI,gBAAgB;YAClB,aAAa;QACf;QAEA,OAAO,iBACH;YACE,GAAG,OAAO;YACV,OAAO;QACT,IACA;IACN;IAEA,6DAA6D;IAC7D,MAAM,kBAAkB,mBACrB,KAAK,GACL,OAAO,GACP,IAAI,CAAC,CAAC,MAAQ,IAAI,IAAI,KAAK;IAE9B,MAAM,cAAc,kBAAkB;QAAC;KAAgB,GAAG,EAAE;IAE5D,OAAO;QAAE,UAAU;QAAoB;QAAa;IAAW;AACjE;AAEA;;;CAGC,GACD,MAAM,8BAA8B,CAClC,UACA;IAEA,8DAA8D;IAC9D,IAAI,SAAS,IAAI,KAAK,yBAAyB;QAC7C,OAAO,0BACL,UACA;IAEJ;IAEA,sEAAsE;IACtE,OAAO,yBAAyB;AAClC;AAEA;;CAEC,GACD,MAAM,4BAA4B,CAChC,cACA;IAEA,MAAM,SAAS,gBAAgB,GAAG,CAAC,aAAa,UAAU,KAAK;IAE/D,OAAO;QACL,MAAM;QACN,YAAY,aAAa,UAAU;QACnC,OAAO;QACP,OAAO,aAAa,KAAK;QACzB,QAAQ;YACN,QAAQ;gBACN,UAAU;gBACV,QAAQ;gBACR,QACE,OAAO,MAAM,KAAK,IAAI,wCAAwC;YAClE;QACF;IACF;AACF;AAEA;;CAEC,GACD,MAAM,2BAA2B,CAAC;IAChC,8DAA8D;IAC9D,OAAQ,SAAS,IAAI;QACnB,KAAK;YACH,OAAO;gBACL,GAAG,QAAQ;gBACX,OAAO;gBACP,QAAQ;oBACN,QAAQ;oBACR,QAAQ;wBAAE,WAAW;wBAAG,OAAO;oBAAE;oBACjC,cAAc,EAAE;gBAClB;YACF;QAEF;YACE,+DAA+D;YAC/D,OAAO;gBACL,GAAG,QAAQ;gBACX,OAAO;gBACP,QAAQ;oBACN,QAAQ;gBACV;YACF;IACJ;AACF"}},
    {"offset": {"line": 797, "column": 0}, "map": {"version":3,"sources":["file:///home/runner/workspace/types/chat.ts"],"sourcesContent":["import { UIMessage } from \"ai\";\nimport { z } from \"zod\";\nimport { Id } from \"@/convex/_generated/dataModel\";\nimport type { FileDetails } from \"./file\";\n\nexport type ChatMode = \"agent\" | \"ask\";\n\nexport type SubscriptionTier = \"free\" | \"pro\" | \"ultra\" | \"team\";\n\nexport interface SidebarFile {\n  path: string;\n  content: string;\n  language?: string;\n  range?: {\n    start: number;\n    end: number;\n  };\n  action?: \"reading\" | \"creating\" | \"editing\" | \"writing\";\n  toolCallId?: string;\n  /** Original content before edit (for diff view) */\n  originalContent?: string;\n  /** Modified content after edit (for diff view) */\n  modifiedContent?: string;\n}\n\nexport interface SidebarTerminal {\n  command: string;\n  output: string;\n  isExecuting: boolean;\n  isBackground?: boolean;\n  pid?: number | null;\n  toolCallId: string;\n}\n\nexport interface SidebarPython {\n  code: string;\n  output: string;\n  isExecuting: boolean;\n  toolCallId: string;\n}\n\nexport type SidebarContent = SidebarFile | SidebarTerminal | SidebarPython;\n\nexport const isSidebarFile = (\n  content: SidebarContent,\n): content is SidebarFile => {\n  return \"path\" in content;\n};\n\nexport const isSidebarTerminal = (\n  content: SidebarContent,\n): content is SidebarTerminal => {\n  return \"command\" in content && !(\"code\" in content);\n};\n\nexport const isSidebarPython = (\n  content: SidebarContent,\n): content is SidebarPython => {\n  return \"code\" in content;\n};\n\nexport interface Todo {\n  id: string;\n  content: string;\n  status: \"pending\" | \"in_progress\" | \"completed\" | \"cancelled\";\n  sourceMessageId?: string;\n}\n\nexport interface TodoBlockProps {\n  todos: Todo[];\n  inputTodos?: Todo[];\n  blockId: string;\n  messageId: string;\n}\n\nexport interface TodoWriteInput {\n  merge?: boolean;\n  todos?: Todo[];\n}\n\nexport type ChatStatus = \"submitted\" | \"streaming\" | \"ready\" | \"error\";\n\nexport const messageMetadataSchema = z.object({\n  feedbackType: z.enum([\"positive\", \"negative\"]),\n});\n\nexport type MessageMetadata = z.infer<typeof messageMetadataSchema>;\n\nexport type ChatMessage = UIMessage<MessageMetadata> & {\n  fileDetails?: FileDetails[];\n  sourceMessageId?: string;\n};\n\nexport type RateLimitInfo = {\n  remaining: number;\n  resetTime: Date;\n  limit: number;\n};\n\nexport interface QueuedMessage {\n  id: string;\n  text: string;\n  files?: Array<{\n    file: File;\n    fileId: Id<\"files\">;\n    url: string;\n  }>;\n  timestamp: number;\n}\n\nexport type QueueBehavior = \"queue\" | \"stop-and-send\";\n\n// Sandbox preference: \"e2b\" for cloud, or a connection ID for local sandbox\nexport type SandboxPreference = \"e2b\" | string;\n"],"names":[],"mappings":";;;;;;;;;;AACA;;AA0CO,MAAM,gBAAgB,CAC3B;IAEA,OAAO,UAAU;AACnB;AAEO,MAAM,oBAAoB,CAC/B;IAEA,OAAO,aAAa,WAAW,CAAC,CAAC,UAAU,OAAO;AACpD;AAEO,MAAM,kBAAkB,CAC7B;IAEA,OAAO,UAAU;AACnB;AAuBO,MAAM,wBAAwB,mOAAC,CAAC,MAAM,CAAC;IAC5C,cAAc,mOAAC,CAAC,IAAI,CAAC;QAAC;QAAY;KAAW;AAC/C"}},
    {"offset": {"line": 828, "column": 0}, "map": {"version":3,"sources":["file:///home/runner/workspace/convex/_generated/api.js"],"sourcesContent":["/* eslint-disable */\n/**\n * Generated `api` utility.\n *\n * THIS CODE IS AUTOMATICALLY GENERATED.\n *\n * To regenerate, run `npx convex dev`.\n * @module\n */\n\nimport { anyApi, componentsGeneric } from \"convex/server\";\n\n/**\n * A utility for referencing Convex functions in your app's API.\n *\n * Usage:\n * ```js\n * const myFunctionReference = api.myModule.myFunction;\n * ```\n */\nexport const api = anyApi;\nexport const internal = anyApi;\nexport const components = componentsGeneric();\n"],"names":[],"mappings":"AAAA,kBAAkB,GAClB;;;;;;;CAOC;;;;;;;;AAED;AAAA;AAAA;;AAUO,MAAM,MAAM,0OAAM;AAClB,MAAM,WAAW,0OAAM;AACvB,MAAM,aAAa,IAAA,qRAAiB"}}]
}